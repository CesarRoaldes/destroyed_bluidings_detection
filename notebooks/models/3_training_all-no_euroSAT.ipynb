{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Entrainement du modèle de détection des bâtiments détruits à partir du modèle Pré-entrainé sur la base euroSAT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par sélectionner le device sur lequel les calculs seront effectués."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 GPU(s) disponible.\n",
      "GPU utilisé : GeForce GTX 1050 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('%d GPU(s) disponible.' % torch.cuda.device_count())\n",
    "    print('GPU utilisé :', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('Pas de GPU disponible, utilisation du CPU.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Création du `DataLoader`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le chargement des images par `PyTorch` nécessite la création d'un objet appelé `DataLoader`. Le `DataLoader` permet de charger les images par batch dans le device (et ne pas surcharger la RAM du GPU) et d'appliquer des transformations sur ces images lors de leur chargement.  \n",
    "  \n",
    "On commence par définir le dictionnaire `data_transforms` contenant les transformations à appliquer sur les images. Nous avons décidé d'appliquer les deux transformations:  \n",
    "- `RandomHorizontalFlip` retourne avec une probabilité de 0.5 l'image par rapport à l'axe horizontal. Cette technique permet d'augmenter artificiellement notre volume de données.  \n",
    "  \n",
    "- `Normalize` permet de normaliser les images sur les 3 canaux RGB. Les valeurs des moyennes et écarts-types utilisés lors de la normalisation correspondent aux valeurs calculées sur les images du data set [ImageNet](http://image-net.org/download). Nous reprenons ces valeurs car les poids du CNN sont préalablemment entraînés sur ces images. (Voir le notebook *2_training_rgb.ipynb*, partie *Calcul des moyennes et écarts-type de nos images*, pour plus de détails)\n",
    "  \n",
    "  \n",
    "Pour finir, le `batch_size` nous permet de fixer le nombre d'images à charger par batch. Ce paramètre est ajusté en fonction de la RAM du GPU sur lequel le modèle sera amené à tourner. Pour accélérer la vitesse de calcul, il faut maximiser le nombre d'images par batch. Cependant, si le nombre d'images par batch est trop élevé, la RAM sature et le modèle ne peut pas s'exécuter.  \n",
    "  \n",
    "Nous analysons l'utilisation de la RAM du GPU à l'aide du programme [gpustat](https://github.com/wookayin/gpustat), et surveillons son état tout au long de l'apprentissage. Le screenshot suivant présente son état initial :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../data/screenshots/GRAM_init.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '../../data/images/all'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Chargement du modèle pre-trained sur euroSAT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous chargeons dans un premier temps le modèle [ResNet50](https://arxiv.org/pdf/1512.03385.pdf) ([doc](https://pytorch.org/docs/stable/torchvision/models.html#torchvision.models.resnet50)) pre-trained sur la base de donné [ImageNet](http://www.image-net.org/) par le biais de l'argument `pretrained=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous modifions la dernière couche, l'*output layer* ( `model.fc` ), pour la faire correspondre au nombre de labels de notre base ( `0` / `1` )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Phase d'apprentissage sur la base complète (Alep + Ezzor)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `train_model` permet de fit le CNN. Elle utilise une loss et un optimizer chargé de mettre à jour les poids par backpropagation.  La fonction retourne le modèle de de l'epoch ayant obtenue le meilleur score sur le test set. Nous évitons ainsi de faire du surapprentissage.\n",
    "  \n",
    "[Ref code pytorch](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    # dictionnaire regroupant les statistique lors de l'apprentissage\n",
    "    info = {'train':{'loss':[], 'accuracy':[]}, 'test':{'loss':[], 'accuracy':[]}}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Chaque epoch a une phase d'apprentissage (train) et de validation (test)\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Active le mode apprentissage du modèle\n",
    "            else:\n",
    "                model.eval()   # Active le mode d'evaluation du modèle\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Itere sur les donnees\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # fixe les parametres du gradient a zero\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # garde l'historique si phase d'apprentissage\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backpropagation et optimisation lors de l'apprentissage\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistiques\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            # on remplit les dictionnaires avec les infos de l'epoch\n",
    "            info[phase]['loss'].append(epoch_loss)\n",
    "            info[phase]['accuracy'].append(float(epoch_acc.detach().cpu().numpy()))\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # sauvegarde du modele le plus performant\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best test Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # charge les poids du meilleur modele avant de le retourner\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour entraîner le modèle sur nos images nous avons choisi la stratégie d'optimisation suivante :\n",
    "\n",
    "  \n",
    "- <u>Fonction de perte</u> : Cross Entropy ([ref](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss))\n",
    "- <u>Optimizer</u> : Adam ([ref](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam)). Nous avons décidé d'effectuer l'optimisation de tous les paramètres du modèles et pas uniquement ceux de la fully connected layer. La phase d'apprentissage prenant plus de 10h pour s'effectuer nous n'avons pas pu tester les différentes possibiltés pour le choix de nos hyperparamètres. Nous avons donc décidé de choisir les valeurs conseillés dans le [papier original](https://arxiv.org/pdf/1412.6980.pdf). \n",
    "- <u>Scheduler</u> : un scheduler qui fait décroitre le learning rate 0.1 toutes 15 itérations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Remarque* : La phase d'apprentissage s'effectue sur l'ensemble des paramètres du modèle. Il serait intéressant de ne considérer que la dernière couche *fully connected (fc)* lors de l'optimisation du modèle et comparer avec les résultats obtenus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# On optimise sur tout les paramètres\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# Pour effectuer l'apprentissage sur la couche fc remplacer model.parameters par :\n",
    "# model_ft.fc.parameters()\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'envoi du modèle vers le GPU utilise une part non négligeable de sa RAM (près de 500MB) lorsque l'on utilise un modèle tel que ResNet50 contenant 25,6 millions de paramètres. L'état de la GRAM après cette étape est présentée dans l'image suivante :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../data/screenshots/GRAM_model.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lancement de la phase d'apprentissage sur 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, info = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fois-ci, les données sont envoyées dans la GRAM par batch de 4 images. Comme expliquée auparavant, l'objectif est de maximiser le nombre d'image par batch sous contraintes des capacitées de mémoire du GPU. L'image suivante témoigne du la mémoire prise par ces 4 images (en plus du modèle) :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../data/screenshots/GRAM_train.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sauvegarde des poids du modèle ( `state_dict` )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../../data/model'\n",
    "os.makedirs(os.path.join(model_dir), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(model_dir, 'all_model_no_euroSAT.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sauvegarde des informations sur la phase d'apprentissage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(info, open(os.path.join(model_dir, 'all_model_no_euroSAT_info.pkl'), 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sat]",
   "language": "python",
   "name": "conda-env-sat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
