{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-89a14f2eee2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os \n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import geopandas\n",
    "import geoplot\n",
    "import pandas as pd\n",
    "import geoplot as gplt\n",
    "import geoplot.crs as gcrs\n",
    "import geopandas as gpd\n",
    "\n",
    "from shapely import wkt\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../../data/'\n",
    "MODEL_DIR = os.path.join(DATA_DIR, 'model')\n",
    "GRAPH_DIR = os.path.join(DATA_DIR, 'graphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(path):\n",
    "    with open(os.path.abspath(path), 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_transform():   \n",
    "    transf = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])    \n",
    "\n",
    "    return transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_tensors(img):\n",
    "    transf = get_input_transform()\n",
    "    return transf(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_image_path(image_path, model):\n",
    "    \"\"\" Sort les predictions d'un model sur l'image\n",
    "        passee en arguement.\n",
    "    \"\"\"\n",
    "    img = get_image(image_path)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    img_t = get_input_tensors(img)\n",
    "    img_t = img_t.to(device)\n",
    "    \n",
    "    output = model(img_t)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    \n",
    "    pred = pred.detach().cpu().numpy()[0]\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(description):\n",
    "    \n",
    "    #set up le GPU\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print('%d GPU(s) disponible.' % torch.cuda.device_count())\n",
    "        print('GPU utilisé :', torch.cuda.get_device_name(0))\n",
    "\n",
    "    else:\n",
    "        print('Pas de GPU disponible, utilisation du CPU.')\n",
    "        device = torch.device(\"cpu\")\n",
    "    \n",
    "    #charge le dataset\n",
    "    \n",
    "    data_preds = pd.read_csv(os.path.join(DATA_DIR, 'images_label_' + description + '.csv')\n",
    "    \n",
    "    #charge le modele\n",
    "    \n",
    "    model_euroSAT = models.resnet50(pretrained=False, progress=True)\n",
    "    num_ftrs = model_euroSAT.fc.in_features\n",
    "    model_euroSAT.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_euroSAT.load_state_dict(torch.load(os.path.join(MODEL_DIR, )))\n",
    "    \n",
    "    #run le modele\n",
    "    \n",
    "    pred_euroSAT = []\n",
    "\n",
    "    for idx, obs in damas_preds.iterrows():\n",
    "        image_nom = obs['nom_images_torchvision']\n",
    "        image_path = os.path.join('/content/', 'damas', obs['segment'], str(obs['label']), image_nom)\n",
    "        #pred_no_euroSAT.append(prediction_image_path(image_path, model_no_euroSAT))\n",
    "        pred_euroSAT.append(prediction_image_path(image_path, model_euroSAT))\n",
    "        \n",
    "    data_preds['pred_euroSAT'] = pred_euroSAT\n",
    "    \n",
    "    #sauvegarde le modèle\n",
    "    \n",
    "    damas_preds.to_csv(os.path.join(DATA_DIR, 'images_label&pred_' + description +'.csv', index=False)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_map():\n",
    "    \n",
    "    #charge le data set\n",
    "    data = pd.read_csv(#chercher le csv ecrit par run_model)\n",
    "    \n",
    "    #prepare les données\n",
    "    data['geometry'] = data['centroide']\n",
    "    data['Coordinates'] = data['centroide'].apply(wkt.loads)\n",
    "    data = data.set_geometry('Coordinates')\n",
    "    \n",
    "        \n",
    "    #fait la map\n",
    "    \n",
    "    fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(20, 10), subplot_kw={'projection': gcrs.WebMercator()})\n",
    "\n",
    "    gplt.webmap(data, projection=gcrs.WebMercator(), ax=axes[0])\n",
    "    gplt.pointplot(data[data['label'] == 1], ax=axes[0], alpha=1, s=2, color='k')\n",
    "    gplt.kdeplot(data_preds[data['pred_euroSAT'] == 1], cmap='RdYlGn_r', n_levels=30,\n",
    "                 shade=True, shade_lowest=False, ax=axes[0], alpha=0.5)\n",
    "\n",
    "    gplt.webmap(data, projection=gcrs.WebMercator(), ax=axes[1])\n",
    "    gplt.pointplot(data[data['label'] == 1], ax=axes[1], alpha=1, s=2, color='k',\n",
    "                   label='Geolocalization of destroyed buildings')\n",
    "    gplt.kdeplot(data_preds[data['pred_euroSAT'] == 1], cmap='RdYlGn_r', n_levels=30,\n",
    "                 shade=True, shade_lowest=False, ax=axes[1], alpha=0.5,\n",
    "                 label='Predicted density of destroyed buildings')\n",
    "\n",
    "    axes[0].set_title('Not pretrained model', fontsize=15)\n",
    "    axes[1].set_title('Pretrained model on euroSAT', fontsize=15)\n",
    "    plt.legend(bbox_to_anchor=(-0.75, -0.075, 0.5, -0.185), loc='lower left',\n",
    "               ncol=2, borderaxespad=0., fontsize=15)\n",
    "    fig.suptitle('Models predictions on Alep', fontsize=20, y=0.95)\n",
    "    fig.subplots_adjust(wspace=0)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
